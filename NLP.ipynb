{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54bcb385",
   "metadata": {},
   "source": [
    "# NLP : Author Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9dfec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PCZ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PCZ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PCZ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c7fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb773dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth1_url1 = \"https://www.gutenberg.org/files/786/786-0.txt\"\n",
    "auth1_url2 = \"https://www.gutenberg.org/files/564/564-0.txt\"\n",
    "auth1_url3 = \"https://www.gutenberg.org/files/675/675-0.txt\"\n",
    "auth1_url4 = \"https://www.gutenberg.org/files/98/98-0.txt\"\n",
    "auth1_url5 = \"https://www.gutenberg.org/files/650/650-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f9d00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth2_url1 = \"https://www.gutenberg.org/files/141/141-0.txt\"\n",
    "auth2_url2 = \"https://www.gutenberg.org/cache/epub/21839/pg21839.txt\"\n",
    "auth2_url3 = \"https://www.gutenberg.org/cache/epub/42671/pg42671.txt\"\n",
    "auth2_url4 = \"https://www.gutenberg.org/cache/epub/105/pg105.txt\"\n",
    "auth2_url5 = \"https://www.gutenberg.org/files/121/121-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a159e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth3_url1 = \"https://www.gutenberg.org/files/108/108-0.txt\"\n",
    "auth3_url2 = \"https://www.gutenberg.org/files/834/834-0.txt\"\n",
    "auth3_url3 = \"https://www.gutenberg.org/files/903/903-0.txt\"\n",
    "auth3_url4 = \"https://www.gutenberg.org/files/48320/48320-0.txt\"\n",
    "auth3_url5 = \"https://www.gutenberg.org/files/54109/54109-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d9cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth4_url1 = \"https://www.gutenberg.org/files/28289/28289-0.txt\"\n",
    "auth4_url2 = \"https://www.gutenberg.org/cache/epub/17780/pg17780.txt\"\n",
    "auth4_url3 = \"https://www.gutenberg.org/files/550/550-0.txt\"\n",
    "auth4_url4 = \"https://www.gutenberg.org/cache/epub/47025/pg47025.txt\"\n",
    "auth4_url5 = \"https://www.gutenberg.org/files/10762/10762.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1689eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth5_url1 = \"https://www.gutenberg.org/cache/epub/60278/pg60278.txt\"\n",
    "auth5_url2 = \"https://www.gutenberg.org/cache/epub/66837/pg66837.txt\"\n",
    "auth5_url3 = \"https://www.gutenberg.org/files/60327/60327-0.txt\"\n",
    "auth5_url4 = \"https://www.gutenberg.org/files/3474/3474-0.txt\"\n",
    "auth5_url5 = \"https://www.gutenberg.org/cache/epub/27180/pg27180.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87108837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fragments(url, L):\n",
    "    #Read the file\n",
    "    file = urllib.request.urlopen(url)\n",
    "    lines = []\n",
    "    for line in file :\n",
    "        decoded_line = line.decode(\"utf-8\")\n",
    "        lines.append(decoded_line.strip())\n",
    "    \n",
    "    #Change the letters to lower case\n",
    "    raw_docs = [doc.lower() for doc in lines]\n",
    "    while (\"\" in raw_docs) :\n",
    "        raw_docs.remove(\"\")\n",
    "    \n",
    "    #Word tokenization\n",
    "    tokenized_doc = [word_tokenize(doc) for doc in raw_docs]\n",
    "    \n",
    "    #Remove the punctuations\n",
    "    regex = re.compile('[%s]'% re.escape(string.punctuation))\n",
    "    tokenized_docs_no_punc = []\n",
    "    for review in tokenized_doc :\n",
    "        new_review = []\n",
    "        for token in review :\n",
    "            new_token = regex.sub(u'', token)\n",
    "            if not new_token == u'' :\n",
    "                new_review.append(new_token)\n",
    "        tokenized_docs_no_punc.append(new_review)\n",
    "    \n",
    "    puncs = [\"’\", \"‘\", \"“\", \"”\"]\n",
    "    for punc in puncs :\n",
    "        for line in tokenized_docs_no_punc :\n",
    "            while(punc in line) :\n",
    "                line.remove(punc)\n",
    "    \n",
    "    #Remove the stop words\n",
    "    tokenized_doc_no_sw = []\n",
    "    for doc in tokenized_docs_no_punc :\n",
    "        new_term_vector = []\n",
    "        for word in doc :\n",
    "            if not word in stopwords.words('english') :\n",
    "                new_term_vector.append(word)\n",
    "        tokenized_doc_no_sw.append(new_term_vector)\n",
    "    \n",
    "    lists = []\n",
    "    for line in tokenized_doc_no_sw:\n",
    "        lines = []\n",
    "        for word in line:\n",
    "            lines.append(\"\".join(u for u in word if u not in (\"—\")))\n",
    "        lists.append(lines)\n",
    "    \n",
    "    #Use the lemmantization to get the root words\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    pre_docs = []\n",
    "    for doc in lists :\n",
    "        final_doc = []\n",
    "        for word in doc :\n",
    "            final_doc.append(wordnet.lemmatize(word))\n",
    "        pre_docs.append(final_doc)\n",
    "    \n",
    "    #Extracting L number of fragments in size of 200\n",
    "    final_list = []\n",
    "    i = 199\n",
    "    while len(final_list) < 200 :\n",
    "            line = pre_docs[i+1]\n",
    "            while len(line) <= L:\n",
    "                i = i + 2\n",
    "                for word in pre_docs[i]:\n",
    "                    line.append(word)\n",
    "            final_list.append(' '.join(line[0:L]))\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b218f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57f5b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth1_list1 = extract_fragments(auth1_url1, L)\n",
    "auth1_list2 = extract_fragments(auth1_url2, L)\n",
    "auth1_list3 = extract_fragments(auth1_url3, L)\n",
    "auth1_list4 = extract_fragments(auth1_url4, L)\n",
    "auth1_list5 = extract_fragments(auth1_url5, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96b72b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [*auth1_list1, *auth1_list2, *auth1_list3, *auth1_list4, *auth1_list5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74f2869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth2_list1 = extract_fragments(auth2_url1, L)\n",
    "auth2_list2 = extract_fragments(auth2_url2, L)\n",
    "auth2_list3 = extract_fragments(auth2_url3, L)\n",
    "auth2_list4 = extract_fragments(auth2_url4, L)\n",
    "auth2_list5 = extract_fragments(auth2_url5, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad1d7436",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = [*auth2_list1, *auth2_list2, *auth2_list3, *auth2_list4, *auth2_list5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cb8c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth3_list1 = extract_fragments(auth3_url1, L)\n",
    "auth3_list2 = extract_fragments(auth3_url2, L)\n",
    "auth3_list3 = extract_fragments(auth3_url3, L)\n",
    "auth3_list4 = extract_fragments(auth3_url4, L)\n",
    "auth3_list5 = extract_fragments(auth3_url5, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ddc6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 = [*auth3_list1, *auth3_list2, *auth3_list3, *auth3_list4, *auth3_list5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d60b6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth4_list1 = extract_fragments(auth4_url1, L)\n",
    "auth4_list2 = extract_fragments(auth4_url2, L)\n",
    "auth4_list3 = extract_fragments(auth4_url3, L)\n",
    "auth4_list4 = extract_fragments(auth4_url4, L)\n",
    "auth4_list5 = extract_fragments(auth4_url5, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9fdadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list4 = [*auth4_list1, *auth4_list2, *auth4_list3, *auth4_list4, *auth4_list5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da4caa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth5_list1 = extract_fragments(auth5_url1, L)\n",
    "auth5_list2 = extract_fragments(auth5_url2, L)\n",
    "auth5_list3 = extract_fragments(auth5_url3, L)\n",
    "auth5_list4 = extract_fragments(auth5_url4, L)\n",
    "auth5_list5 = extract_fragments(auth5_url5, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02b175e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list5 = [*auth5_list1, *auth5_list2, *auth5_list3, *auth5_list4, *auth5_list5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d116d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "x = [*list1, *list2, *list3, *list4, *list5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ee20ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,\n",
       " 'beginning sunbeam bitzer corner row side row advance caught end receive deeper lustrous colour sun shone ray appeared draw little colour ever possessed lash bringing immediate contrast something might mere continuation sandy freckle forehead looked though cut would bleed white quadruped graminivorous forty teeth namely twentyfour grinder country shed hoof')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x), x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d05d16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = ['Charles Dickens', 'Jane Austen', 'Sir Arthur Conan Doyle', 'George Eliot', 'Hugh Walpole']\n",
    "target = []\n",
    "for author in authors :\n",
    "    for i in range(0, 1000):\n",
    "        target.append(author)\n",
    "y = LabelEncoder().fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0dfb28bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, {0, 1, 2, 3, 4})"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y), set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a116bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame({\n",
    "    'Extracted Fragments' : [],\n",
    "    'Author' : []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ede00436",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(x)) :\n",
    "    data_df = data_df.append({\n",
    "        'Extracted Fragments' : x[i],\n",
    "        'Author' : target[i],\n",
    "    }, ignore_index = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9eb47602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extracted Fragments</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beginning sunbeam bitzer corner row side row a...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iron age known mark mouth thus much bitzer gir...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continue fistic phraseology genius coming scra...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ventured answer paper room would paint must pa...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>general conviction time sir always feeble stra...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>robin rate made meaning clear wish regard comp...</td>\n",
       "      <td>Hugh Walpole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>omitted mine came back stranger ready anything...</td>\n",
       "      <td>Hugh Walpole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>see please shall course disguise position worl...</td>\n",
       "      <td>Hugh Walpole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>end would father said show stiff back white mo...</td>\n",
       "      <td>Hugh Walpole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>felt confinement wished something broader well...</td>\n",
       "      <td>Hugh Walpole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Extracted Fragments           Author\n",
       "0     beginning sunbeam bitzer corner row side row a...  Charles Dickens\n",
       "1     iron age known mark mouth thus much bitzer gir...  Charles Dickens\n",
       "2     continue fistic phraseology genius coming scra...  Charles Dickens\n",
       "3     ventured answer paper room would paint must pa...  Charles Dickens\n",
       "4     general conviction time sir always feeble stra...  Charles Dickens\n",
       "...                                                 ...              ...\n",
       "4995  robin rate made meaning clear wish regard comp...     Hugh Walpole\n",
       "4996  omitted mine came back stranger ready anything...     Hugh Walpole\n",
       "4997  see please shall course disguise position worl...     Hugh Walpole\n",
       "4998  end would father said show stiff back white mo...     Hugh Walpole\n",
       "4999  felt confinement wished something broader well...     Hugh Walpole\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "622effa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('Dataset_L50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82beb88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5428d1e5",
   "metadata": {},
   "source": [
    "## BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8148d8b4",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4dc5b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "x_train_bow = bow.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "27edc188",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_par = {\n",
    "    'penalty' : ['l2'],\n",
    "    'C' : [0.1, 1.0, 10.0],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'max_iter' : [100, 200, 300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01c60814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "lr_grid = GridSearchCV(LR, lr_par, refit = True, n_jobs=-1, cv=5)\n",
    "lr_grid.fit(x_train_bow, y_train)\n",
    "opt_par = lr_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e572d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_acc_bow = []\n",
    "lr_test_acc_bow = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    bow = CountVectorizer()\n",
    "    x_train_bow = bow.fit_transform(x_train)\n",
    "    x_test_bow = bow.transform(x_test)\n",
    "    LR = LogisticRegression(C = 10.0, max_iter = 100, penalty = 'l2', solver = 'newton-cg')\n",
    "    LR.fit(x_train_bow, y_train)\n",
    "    y_pred = LR.predict(x_test_bow)\n",
    "    y_train_pred = LR.predict(x_train_bow)\n",
    "    lr_train_acc_bow.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    lr_test_acc_bow.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8c2ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mean_train_acc_bow = sum(lr_train_acc_bow)/len(lr_train_acc_bow)\n",
    "lr_mean_test_acc_bow = sum(lr_test_acc_bow)/len(lr_test_acc_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "812fd6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9194000000000001)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mean_train_acc_bow, lr_mean_test_acc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869eafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ebce1d5",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d02614ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train_bow = bow.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5660a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_par = [\n",
    "   { 'C' : [0.1, 1.0, 10.0],\n",
    "    'kernel' : ['linear']\n",
    "   },\n",
    "   { 'C' : [0.1, 1.0, 10.0],\n",
    "    'kernel' : ['poly'],\n",
    "    'degree' : [2, 3, 4],\n",
    "    'gamma' : ['scale', 'auto']\n",
    "   },\n",
    "   { 'C' : [0.1, 1.0, 10.0],\n",
    "    'kernel' : ['rbf', 'sigmoid'],\n",
    "    'gamma' : ['scale', 'auto']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "62259f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = SVC()\n",
    "svm_grid = GridSearchCV(SVM, svm_par, refit = True, n_jobs=-1, cv=5)\n",
    "svm_grid.fit(x_train_bow, y_train)\n",
    "opt_par = svm_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d1283699",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train_acc_bow = []\n",
    "svm_test_acc_bow = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    bow = CountVectorizer()\n",
    "    x_train_bow = bow.fit_transform(x_train)\n",
    "    x_test_bow = bow.transform(x_test)\n",
    "    SVM = SVC( C = 0.1, kernel = 'linear' )\n",
    "    SVM.fit(x_train_bow, y_train)\n",
    "    y_pred = SVM.predict(x_test_bow)\n",
    "    y_train_pred = SVM.predict(x_train_bow)\n",
    "    svm_train_acc_bow.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    svm_test_acc_bow.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b927fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mean_train_acc_bow = sum(svm_train_acc_bow)/len(svm_train_acc_bow)\n",
    "svm_mean_test_acc_bow = sum(svm_test_acc_bow)/len(svm_test_acc_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "726b9fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9016499999999998)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_mean_train_acc_bow, svm_mean_test_acc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b518d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21b2c55b",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "782c2a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train_bow = bow.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "82d9ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_par = {\n",
    "    'n_estimators' : [50, 100, 200],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [8, 16, 32],\n",
    "    'max_features' : ['sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "35f0485f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 32,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(RF, rf_par, refit = True, n_jobs=-1, cv=5)\n",
    "rf_grid.fit(x_train_bow, y_train)\n",
    "opt_par = rf_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9bcd9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_acc_bow = []\n",
    "rf_test_acc_bow = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    bow = CountVectorizer()\n",
    "    x_train_bow = bow.fit_transform(x_train)\n",
    "    x_test_bow = bow.transform(x_test)\n",
    "    RF = RandomForestClassifier(criterion = 'gini', max_depth = 32, max_features = 'log2', n_estimators = 200 )\n",
    "    RF.fit(x_train_bow, y_train)\n",
    "    y_pred = RF.predict(x_test_bow)\n",
    "    y_train_pred = RF.predict(x_train_bow)\n",
    "    rf_train_acc_bow.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    rf_test_acc_bow.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fa5206f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_mean_train_acc_bow = sum(rf_train_acc_bow)/len(rf_train_acc_bow)\n",
    "rf_mean_test_acc_bow = sum(rf_test_acc_bow)/len(rf_test_acc_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1a1bd0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9998250000000001, 0.86775)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mean_train_acc_bow, rf_mean_test_acc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3158abe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "158c3e80",
   "metadata": {},
   "source": [
    "### Naive Bays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "77ce61da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_acc_bow = []\n",
    "nb_test_acc_bow = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    bow = CountVectorizer()\n",
    "    x_train_bow = bow.fit_transform(x_train)\n",
    "    x_test_bow = bow.transform(x_test)\n",
    "    NB = MultinomialNB()\n",
    "    NB.fit(x_train_bow, y_train)\n",
    "    y_pred = NB.predict(x_test_bow)\n",
    "    y_train_pred = NB.predict(x_train_bow)\n",
    "    nb_train_acc_bow.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    nb_test_acc_bow.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "75646e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_mean_train_acc_bow = sum(nb_train_acc_bow)/len(nb_train_acc_bow)\n",
    "nb_mean_test_acc_bow = sum(nb_test_acc_bow)/len(nb_test_acc_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0e6c636e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.991, 0.9328000000000001)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_mean_train_acc_bow, nb_mean_test_acc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a8a636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70265bd5",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e185a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train_bow = bow.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5fd4a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_par = {\n",
    "    'n_estimators' : [20, 50, 100],\n",
    "    'use_label_encoder' : [False],\n",
    "    'max_depth' : [8, 16, 32],\n",
    "    'learning_rate' : [0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d50e2b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:58:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 8,\n",
       " 'n_estimators': 100,\n",
       " 'use_label_encoder': False}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB = XGBClassifier()\n",
    "xgb_grid = GridSearchCV(XGB, xgb_par, refit = True, n_jobs=-1, cv=5)\n",
    "xgb_grid.fit(x_train_bow, y_train)\n",
    "opt_par = xgb_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "16ffaf9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:26:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:26:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:26:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:26:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:27:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:27:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:27:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:28:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:28:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:28:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:28:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:31:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_train_acc_bow = []\n",
    "xgb_test_acc_bow = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    bow = CountVectorizer()\n",
    "    x_train_bow = bow.fit_transform(x_train)\n",
    "    x_test_bow = bow.transform(x_test)\n",
    "    XGB = XGBClassifier(learning_rate = 0.1, max_depth = 8, n_estimators = 100, use_label_encoder = False )\n",
    "    XGB.fit(x_train_bow, y_train)\n",
    "    y_pred = XGB.predict(x_test_bow)\n",
    "    y_train_pred = XGB.predict(x_train_bow)\n",
    "    xgb_train_acc_bow.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    xgb_test_acc_bow.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d23de49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_mean_train_acc_bow = sum(xgb_train_acc_bow)/len(xgb_train_acc_bow)\n",
    "xgb_mean_test_acc_bow = sum(xgb_test_acc_bow)/len(xgb_test_acc_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6380840f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.984675, 0.8283499999999998)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mean_train_acc_bow, xgb_mean_test_acc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754619d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "435b498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['Logistic Regression', 'Support Vector Machine', 'Random Forest', 'Naive Bayes', 'XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c19bfd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_df = pd.DataFrame({\n",
    "    'Algorithm' : [], \n",
    "    'Train Accuracies' : [],\n",
    "    'Mean Train Accuracy' : [],\n",
    "    'Test Accuracies' : [],\n",
    "    'Mean Test Accuracy' :[]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c6b3f109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_bow = [lr_train_acc_bow, svm_train_acc_bow, rf_train_acc_bow,\n",
    "                      nb_train_acc_bow, xgb_train_acc_bow]\n",
    "test_acc_bow = [lr_test_acc_bow, svm_test_acc_bow, rf_test_acc_bow,\n",
    "                    nb_test_acc_bow, xgb_test_acc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "76120d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_acc_bow = [lr_mean_train_acc_bow, svm_mean_train_acc_bow, rf_mean_train_acc_bow,\n",
    "                      nb_mean_train_acc_bow, xgb_mean_train_acc_bow]\n",
    "mean_test_acc_bow = [lr_mean_test_acc_bow, svm_mean_test_acc_bow, rf_mean_test_acc_bow,\n",
    "                    nb_mean_test_acc_bow, xgb_mean_test_acc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9a8681ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(algorithms)) :\n",
    "    bow_df = bow_df.append({\n",
    "        'Algorithm' : algorithms[i],\n",
    "        'Train Accuracies' : train_acc_bow[i],\n",
    "        'Mean Train Accuracy' : mean_train_acc_bow[i],\n",
    "        'Test Accuracies' : test_acc_bow[i],\n",
    "        'Mean Test Accuracy' : mean_test_acc_bow[i],\n",
    "    }, ignore_index = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "264a906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Train Accuracies</th>\n",
       "      <th>Mean Train Accuracy</th>\n",
       "      <th>Test Accuracies</th>\n",
       "      <th>Mean Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.922, 0.915, 0.902, 0.925, 0.907, 0.922, 0.9...</td>\n",
       "      <td>0.91940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.906, 0.901, 0.879, 0.912, 0.887, 0.897, 0.9...</td>\n",
       "      <td>0.90165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>[0.99975, 1.0, 1.0, 1.0, 0.99975, 0.99925, 1.0...</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>[0.87, 0.878, 0.861, 0.876, 0.869, 0.852, 0.86...</td>\n",
       "      <td>0.86775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>[0.992, 0.99175, 0.992, 0.99075, 0.9905, 0.991...</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>[0.939, 0.946, 0.928, 0.937, 0.934, 0.93, 0.92...</td>\n",
       "      <td>0.93280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>[0.984, 0.985, 0.9865, 0.98525, 0.98375, 0.985...</td>\n",
       "      <td>0.984675</td>\n",
       "      <td>[0.841, 0.828, 0.817, 0.832, 0.826, 0.82, 0.82...</td>\n",
       "      <td>0.82835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm                                   Train Accuracies  \\\n",
       "0     Logistic Regression  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  Support Vector Machine  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "2           Random Forest  [0.99975, 1.0, 1.0, 1.0, 0.99975, 0.99925, 1.0...   \n",
       "3             Naive Bayes  [0.992, 0.99175, 0.992, 0.99075, 0.9905, 0.991...   \n",
       "4                 XGBoost  [0.984, 0.985, 0.9865, 0.98525, 0.98375, 0.985...   \n",
       "\n",
       "   Mean Train Accuracy                                    Test Accuracies  \\\n",
       "0             1.000000  [0.922, 0.915, 0.902, 0.925, 0.907, 0.922, 0.9...   \n",
       "1             1.000000  [0.906, 0.901, 0.879, 0.912, 0.887, 0.897, 0.9...   \n",
       "2             0.999825  [0.87, 0.878, 0.861, 0.876, 0.869, 0.852, 0.86...   \n",
       "3             0.991000  [0.939, 0.946, 0.928, 0.937, 0.934, 0.93, 0.92...   \n",
       "4             0.984675  [0.841, 0.828, 0.817, 0.832, 0.826, 0.82, 0.82...   \n",
       "\n",
       "   Mean Test Accuracy  \n",
       "0             0.91940  \n",
       "1             0.90165  \n",
       "2             0.86775  \n",
       "3             0.93280  \n",
       "4             0.82835  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "048dafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_df.to_csv('BOW_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca447d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae388c99",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24ec50",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9e744fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(use_idf=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train_tf = tf_idf.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f980cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_par = {\n",
    "    'penalty' : ['l2'],\n",
    "    'C' : [0.1, 1.0, 10.0],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'max_iter' : [100, 200, 300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "551236c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "lr_grid = GridSearchCV(LR, lr_par, refit = True, n_jobs=-1, cv=5)\n",
    "lr_grid.fit(x_train_tf, y_train)\n",
    "opt_par = lr_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2cd631a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_acc_tf = []\n",
    "lr_test_acc_tf = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    tf_idf = TfidfVectorizer(use_idf=True)\n",
    "    x_train_tf = tf_idf.fit_transform(x_train)\n",
    "    x_test_tf = tf_idf.transform(x_test)\n",
    "    LR = LogisticRegression(C = 10.0, max_iter = 200, penalty = 'l2', solver = 'saga')\n",
    "    LR.fit(x_train_tf, y_train)\n",
    "    y_pred = LR.predict(x_test_tf)\n",
    "    y_train_pred = LR.predict(x_train_tf)\n",
    "    lr_train_acc_tf.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    lr_test_acc_tf.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "165f524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mean_train_acc_tf = sum(lr_train_acc_tf)/len(lr_train_acc_tf)\n",
    "lr_mean_test_acc_tf = sum(lr_test_acc_tf)/len(lr_test_acc_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "efd7471e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9442499999999999)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mean_train_acc_tf, lr_mean_test_acc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd91db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "651464be",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e669da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(use_idf=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train_tf = tf_idf.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8dc283ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_par = [\n",
    "   { 'C' : [0.1, 1.0, 10.0],\n",
    "    'kernel' : ['linear']\n",
    "   },\n",
    "   { 'C' : [0.1, 1.0, 10.0],\n",
    "    'kernel' : ['poly'],\n",
    "    'degree' : [2, 3, 4],\n",
    "    'gamma' : ['scale', 'auto']\n",
    "   },\n",
    "   { 'C' : [0.1, 1.0, 10.0],\n",
    "    'kernel' : ['rbf', 'sigmoid'],\n",
    "    'gamma' : ['scale', 'auto']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "29dc34f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = SVC()\n",
    "svm_grid = GridSearchCV(SVM, svm_par, refit = True, n_jobs=-1, cv=5)\n",
    "svm_grid.fit(x_train_tf, y_train)\n",
    "opt_par = svm_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1ac25b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train_acc_tf = []\n",
    "svm_test_acc_tf = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    tf_idf = TfidfVectorizer(use_idf=True)\n",
    "    x_train_tf = tf_idf.fit_transform(x_train)\n",
    "    x_test_tf = tf_idf.transform(x_test)\n",
    "    SVM = SVC( C = 1.0, kernel = 'linear' )\n",
    "    SVM.fit(x_train_tf, y_train)\n",
    "    y_pred = SVM.predict(x_test_tf)\n",
    "    y_train_pred = SVM.predict(x_train_tf)\n",
    "    svm_train_acc_tf.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    svm_test_acc_tf.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ee7e108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mean_train_acc_tf = sum(svm_train_acc_tf)/len(svm_train_acc_tf)\n",
    "svm_mean_test_acc_tf = sum(svm_test_acc_tf)/len(svm_test_acc_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c6523751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9992124999999998, 0.9399999999999998)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_mean_train_acc_tf, svm_mean_test_acc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039cfd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba3a02e4",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bbeab467",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(use_idf=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "x_train_tf = tf_idf.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6db82ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_par = {\n",
    "    'n_estimators' : [50, 100, 200],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [8, 16, 32],\n",
    "    'max_features' : ['sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3f6c9bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 32,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(RF, rf_par, refit = True, n_jobs=-1, cv=5)\n",
    "rf_grid.fit(x_train_tf, y_train)\n",
    "opt_par = rf_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "39179ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_acc_tf = []\n",
    "rf_test_acc_tf = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    tf_idf = TfidfVectorizer(use_idf=True)\n",
    "    x_train_tf = tf_idf.fit_transform(x_train)\n",
    "    x_test_tf = tf_idf.transform(x_test)\n",
    "    RF = RandomForestClassifier(criterion = 'gini', max_depth = 32, max_features = 'log2', n_estimators = 200)\n",
    "    RF.fit(x_train_tf, y_train)\n",
    "    y_pred = RF.predict(x_test_tf)\n",
    "    y_train_pred = RF.predict(x_train_tf)\n",
    "    rf_train_acc_tf.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    rf_test_acc_tf.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "01b7c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_mean_train_acc_tf = sum(rf_train_acc_tf)/len(rf_train_acc_tf)\n",
    "rf_mean_test_acc_tf = sum(rf_test_acc_tf)/len(rf_test_acc_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d46b0a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9893375000000001, 0.788)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mean_train_acc_tf, rf_mean_test_acc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3835b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b14555e",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "eba03991",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_acc_tf = []\n",
    "nb_test_acc_tf = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    tf_idf = TfidfVectorizer(use_idf=True)\n",
    "    x_train_tf = tf_idf.fit_transform(x_train)\n",
    "    x_test_tf = tf_idf.transform(x_test)\n",
    "    NB = MultinomialNB()\n",
    "    NB.fit(x_train_tf, y_train)\n",
    "    y_pred = NB.predict(x_test_tf)\n",
    "    y_train_pred = NB.predict(x_train_tf)\n",
    "    nb_train_acc_tf.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    nb_test_acc_tf.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ee7a0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_mean_train_acc_tf = sum(nb_train_acc_tf)/len(nb_train_acc_tf)\n",
    "nb_mean_test_acc_tf = sum(nb_test_acc_tf)/len(nb_test_acc_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e8d50c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9757000000000001, 0.8935000000000001)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_mean_train_acc_tf, nb_mean_test_acc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ba62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88d6bc7f",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f9da481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(use_idf=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train_tf = tf_idf.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1f079e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_par = {\n",
    "    'n_estimators' : [20, 50, 100],\n",
    "    'use_label_encoder' : [False],\n",
    "    'max_depth' : [8, 16, 32],\n",
    "    'learning_rate' : [0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ae115840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:43:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 8,\n",
       " 'n_estimators': 100,\n",
       " 'use_label_encoder': False}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB = XGBClassifier()\n",
    "xgb_grid = GridSearchCV(XGB, xgb_par, refit = True, n_jobs=-1, cv=5)\n",
    "xgb_grid.fit(x_train_tf, y_train)\n",
    "opt_par = xgb_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e2242119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:49:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:50:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:51:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:52:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:52:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:53:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:54:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:55:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:55:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:56:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:57:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:58:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:58:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:59:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:00:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:00:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:01:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:02:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:03:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:03:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_train_acc_tf = []\n",
    "xgb_test_acc_tf = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    tf_idf = TfidfVectorizer(use_idf=True)\n",
    "    x_train_tf = tf_idf.fit_transform(x_train)\n",
    "    x_test_tf = tf_idf.transform(x_test)\n",
    "    XGB = XGBClassifier(learning_rate = 0.1, max_depth = 8, n_estimators = 100, use_label_encoder = False)\n",
    "    XGB.fit(x_train_tf, y_train)\n",
    "    y_pred = XGB.predict(x_test_tf)\n",
    "    y_train_pred = XGB.predict(x_train_tf)\n",
    "    xgb_train_acc_tf.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    xgb_test_acc_tf.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7e8c44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_mean_train_acc_tf = sum(xgb_train_acc_tf)/len(xgb_train_acc_tf)\n",
    "xgb_mean_test_acc_tf = sum(xgb_test_acc_tf)/len(xgb_test_acc_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "80f99672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9883624999999998, 0.8030000000000002)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mean_train_acc_tf, xgb_mean_test_acc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d0f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ca9d5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['Logistic Regression', 'Support Vector Machine', 'Random Forest', 'Naive Bayes', 'XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2229df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = pd.DataFrame({\n",
    "    'Algorithm' : [],\n",
    "    'Train Accuracies' : [],\n",
    "    'Mean Train Accuracy' : [], \n",
    "    'Test Accuracies' : [],\n",
    "    'Mean Test Accuracy' :[]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "be7209e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_tf = [lr_train_acc_tf, svm_train_acc_tf, rf_train_acc_tf,\n",
    "                      nb_train_acc_tf, xgb_train_acc_tf]\n",
    "test_acc_tf = [lr_test_acc_tf, svm_test_acc_tf, rf_test_acc_tf,\n",
    "                    nb_test_acc_tf, xgb_test_acc_tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1e8358e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_acc_tf = [lr_mean_train_acc_tf, svm_mean_train_acc_tf, rf_mean_train_acc_tf,\n",
    "                      nb_mean_train_acc_tf, xgb_mean_train_acc_tf]\n",
    "mean_test_acc_tf = [lr_mean_test_acc_tf, svm_mean_test_acc_tf, rf_mean_test_acc_tf,\n",
    "                    nb_mean_test_acc_tf, xgb_mean_test_acc_tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9970486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(algorithms)) :\n",
    "    tf_df = tf_df.append({\n",
    "        'Algorithm' : algorithms[i],\n",
    "        'Train Accuracies' : train_acc_tf[i],\n",
    "        'Mean Train Accuracy' : mean_train_acc_tf[i],\n",
    "        'Test Accuracies' : test_acc_tf[i],\n",
    "        'Mean Test Accuracy' : mean_test_acc_tf[i],\n",
    "    }, ignore_index = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2f4545b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Train Accuracies</th>\n",
       "      <th>Mean Train Accuracy</th>\n",
       "      <th>Test Accuracies</th>\n",
       "      <th>Mean Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.949, 0.943, 0.93, 0.944, 0.935, 0.949, 0.94...</td>\n",
       "      <td>0.94425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>[0.99875, 0.99975, 0.99875, 0.99875, 0.9995, 0...</td>\n",
       "      <td>0.999212</td>\n",
       "      <td>[0.943, 0.946, 0.931, 0.947, 0.935, 0.935, 0.9...</td>\n",
       "      <td>0.94000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>[0.989, 0.988, 0.98825, 0.9895, 0.9905, 0.9897...</td>\n",
       "      <td>0.989338</td>\n",
       "      <td>[0.813, 0.781, 0.779, 0.809, 0.787, 0.783, 0.7...</td>\n",
       "      <td>0.78800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>[0.978, 0.977, 0.974, 0.97575, 0.974, 0.96975,...</td>\n",
       "      <td>0.975700</td>\n",
       "      <td>[0.906, 0.896, 0.886, 0.902, 0.891, 0.886, 0.9...</td>\n",
       "      <td>0.89350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>[0.9865, 0.99, 0.988, 0.9885, 0.98925, 0.98925...</td>\n",
       "      <td>0.988362</td>\n",
       "      <td>[0.809, 0.804, 0.794, 0.808, 0.795, 0.8, 0.806...</td>\n",
       "      <td>0.80300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm                                   Train Accuracies  \\\n",
       "0     Logistic Regression  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "1  Support Vector Machine  [0.99875, 0.99975, 0.99875, 0.99875, 0.9995, 0...   \n",
       "2           Random Forest  [0.989, 0.988, 0.98825, 0.9895, 0.9905, 0.9897...   \n",
       "3             Naive Bayes  [0.978, 0.977, 0.974, 0.97575, 0.974, 0.96975,...   \n",
       "4                 XGBoost  [0.9865, 0.99, 0.988, 0.9885, 0.98925, 0.98925...   \n",
       "\n",
       "   Mean Train Accuracy                                    Test Accuracies  \\\n",
       "0             1.000000  [0.949, 0.943, 0.93, 0.944, 0.935, 0.949, 0.94...   \n",
       "1             0.999212  [0.943, 0.946, 0.931, 0.947, 0.935, 0.935, 0.9...   \n",
       "2             0.989338  [0.813, 0.781, 0.779, 0.809, 0.787, 0.783, 0.7...   \n",
       "3             0.975700  [0.906, 0.896, 0.886, 0.902, 0.891, 0.886, 0.9...   \n",
       "4             0.988362  [0.809, 0.804, 0.794, 0.808, 0.795, 0.8, 0.806...   \n",
       "\n",
       "   Mean Test Accuracy  \n",
       "0             0.94425  \n",
       "1             0.94000  \n",
       "2             0.78800  \n",
       "3             0.89350  \n",
       "4             0.80300  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ba55d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df.to_csv('TF-IDF_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f619a2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df11f117",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe03d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('Dataset_L50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7cced6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_df['Extracted Fragments'].values\n",
    "y = LabelEncoder().fit_transform(data_df['Author'])\n",
    "y_enc = pd.get_dummies(data_df['Author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce683ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000, 5000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x), len(y), len(y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602875e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4100a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, GRU, LSTM, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.initializers import Constant\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be6eb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50f81d7d",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b621474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e3571c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f286f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1a4263b",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68843834",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_train_acc_wv = []\n",
    "lstm_val_acc_wv = []\n",
    "lstm_test_acc_wv = []\n",
    "for i in range (0, 20) :\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y_enc, test_size = 0.15, random_state = i + 1)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    x_train_seq  = tokenizer.texts_to_sequences(x_train) \n",
    "    x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "    max_len = max([len(x) for x in x_train_seq])\n",
    "    x_train_pad  = pad_sequences(x_train_seq, padding = 'post', maxlen = max_len)\n",
    "    x_test_pad = pad_sequences(x_test_seq, padding = 'post', maxlen = max_len)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    word_index = tokenizer.word_index\n",
    "    \n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if word in word2vec_model: \n",
    "            embedding_vector = word2vec_model[word]\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    embedding_layer = Embedding(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    weights = [embedding_matrix],\n",
    "    input_length = max_len,\n",
    "    trainable = False\n",
    "    )\n",
    "    \n",
    "    model_wv = Sequential()\n",
    "    model_wv.add(embedding_layer)\n",
    "    model_wv.add(LSTM(units = 64))\n",
    "    model_wv.add(Dropout(0.4))\n",
    "    model_wv.add(Dense(100, activation = 'tanh'))\n",
    "    model_wv.add(Dropout(0.4))\n",
    "    model_wv.add(Dense(5, activation = 'softmax'))\n",
    "\n",
    "    model_wv.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    results_wv_lstm = model_wv.fit(\n",
    "        x_train_pad, \n",
    "        y_train,\n",
    "        batch_size = 8,\n",
    "        epochs = 10, \n",
    "        validation_split = 0.2,\n",
    "        verbose = 0\n",
    "    )\n",
    "    \n",
    "    epoch = len(results_wv_lstm.history['accuracy'])\n",
    "    lstm_train_acc_wv.append(results_wv_lstm.history['accuracy'][epoch - 1])\n",
    "    lstm_val_acc_wv.append(results_wv_lstm.history['val_accuracy'][epoch - 1])\n",
    "    \n",
    "    pred = model_wv.predict(x_test_pad)\n",
    "    predicted_labels = np.argmax ( pred, axis = -1 )\n",
    "    y_test_array = np.argmax ( np.array(y_test), axis = -1 )\n",
    "    test_accuracy = accuracy_score ( y_test_array, predicted_labels )\n",
    "    lstm_test_acc_wv.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4b8e149",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mean_train_acc_wv = sum(lstm_train_acc_wv)/len(lstm_train_acc_wv)\n",
    "lstm_mean_val_acc_wv = sum(lstm_val_acc_wv)/len(lstm_val_acc_wv)\n",
    "lstm_mean_test_acc_wv = sum(lstm_test_acc_wv)/len(lstm_test_acc_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d45702b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.916411766409874, 0.7609999895095825, 0.7664)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_mean_train_acc_wv, lstm_mean_val_acc_wv, lstm_mean_test_acc_wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b356a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fefad51d",
   "metadata": {},
   "source": [
    "## GLoVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2fc742ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "file = open('glove.6B.300d.txt', encoding = \"utf-8\")\n",
    "for line in file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coeff = np.asarray(values[1:], dtype='float32')\n",
    "    embedding_index[word] = coeff\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b95707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e540287d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0b7c329",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b16a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_train_acc_glv = []\n",
    "gru_val_acc_glv = []\n",
    "gru_test_acc_glv = []\n",
    "\n",
    "for i in range (0, 20) :\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y_enc, test_size = 0.2, random_state = i + 1)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    x_train_seq  = tokenizer.texts_to_sequences(x_train) \n",
    "    x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "    max_len = max([len(x) for x in x_train_seq])\n",
    "    x_train_pad  = pad_sequences(x_train_seq, padding = 'post', maxlen = max_len)\n",
    "    x_test_pad = pad_sequences(x_test_seq, padding = 'post', maxlen = max_len)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    word_index = tokenizer.word_index\n",
    "            \n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    embedding_layer = Embedding(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    weights = [embedding_matrix],\n",
    "    input_length = max_len,\n",
    "    trainable = False\n",
    "    )\n",
    "    \n",
    "    model_glv = Sequential()\n",
    "    model_glv.add(embedding_layer)\n",
    "    model_glv.add(GRU(units = 32))\n",
    "    model_glv.add(Dense(5, activation = 'softmax'))\n",
    "\n",
    "    model_glv.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    results_glv_gru = model_glv.fit(\n",
    "        x_train_pad, \n",
    "        y_train, \n",
    "        epochs = 10, \n",
    "        validation_split = 0.2,\n",
    "        verbose = 0\n",
    "    )\n",
    "    \n",
    "    epoch = len(results_glv_gru.history['accuracy'])\n",
    "    gru_train_acc_glv.append(results_glv_gru.history['accuracy'][epoch-1])\n",
    "    gru_val_acc_glv.append(results_glv_gru.history['val_accuracy'][epoch-1])\n",
    "    \n",
    "    pred = model_glv.predict(x_test_pad)\n",
    "    predicted_labels = np.argmax ( pred, axis = -1 )\n",
    "    y_test_array = np.argmax ( np.array(y_test), axis = -1 )\n",
    "    test_accuracy = accuracy_score ( y_test_array, predicted_labels )\n",
    "    gru_test_acc_glv.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3c92cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_mean_train_acc_glv = sum(gru_train_acc_glv)/len(gru_train_acc_glv)\n",
    "gru_mean_val_acc_glv = sum(gru_val_acc_glv)/len(gru_val_acc_glv)\n",
    "gru_mean_test_acc_glv = sum(gru_test_acc_glv)/len(gru_test_acc_glv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "38493147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9694531202316284, 0.8203125, 0.8190999999999999)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_mean_train_acc_glv, gru_mean_val_acc_glv, gru_mean_test_acc_glv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e7feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fbe60bb",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "395a07d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lstm_train_acc_glv = []\n",
    "lstm_val_acc_glv = []\n",
    "lstm_test_acc_glv = []\n",
    "for i in range (0, 20) :\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y_enc, test_size = 0.2, random_state = i + 1)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    x_train_seq  = tokenizer.texts_to_sequences(x_train) \n",
    "    x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "    max_len = max([len(x) for x in x_train_seq])\n",
    "    x_train_pad  = pad_sequences(x_train_seq, padding = 'post', maxlen = max_len)\n",
    "    x_test_pad = pad_sequences(x_test_seq, padding = 'post', maxlen = max_len)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    word_index = tokenizer.word_index\n",
    "            \n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    embedding_layer = Embedding(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    weights = [embedding_matrix],\n",
    "    input_length = max_len,\n",
    "    trainable = False\n",
    "    )\n",
    "    \n",
    "    model_glv = Sequential()\n",
    "    model_glv.add(embedding_layer)\n",
    "    model_glv.add(LSTM(units = 32))\n",
    "    model_glv.add(Dense(5, activation = 'softmax'))\n",
    "\n",
    "    model_glv.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    results_glv_lstm = model_glv.fit(\n",
    "        x_train_pad, \n",
    "        y_train, \n",
    "        epochs = 10, \n",
    "        validation_split = 0.2,\n",
    "        verbose = 0\n",
    "    )\n",
    "    \n",
    "    epoch = len(results_glv_lstm.history['accuracy'])\n",
    "    lstm_train_acc_glv.append(results_glv_lstm.history['accuracy'][epoch-1])\n",
    "    lstm_val_acc_glv.append(results_glv_lstm.history['val_accuracy'][epoch-1])\n",
    "    \n",
    "    pred = model_glv.predict(x_test_pad)\n",
    "    predicted_labels = np.argmax ( pred, axis = -1 )\n",
    "    y_test_array = np.argmax ( np.array(y_test), axis = -1 )\n",
    "    test_accuracy = accuracy_score ( y_test_array, predicted_labels )\n",
    "    lstm_test_acc_glv.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2a2a2915",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mean_train_acc_glv = sum(lstm_train_acc_glv)/len(lstm_train_acc_glv)\n",
    "lstm_mean_val_acc_glv = sum(lstm_val_acc_glv)/len(lstm_val_acc_glv)\n",
    "lstm_mean_test_acc_glv = sum(lstm_test_acc_glv)/len(lstm_test_acc_glv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2cd60184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9628437578678131, 0.7983749985694886, 0.7925000000000001)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_mean_train_acc_glv, lstm_mean_val_acc_glv, lstm_mean_test_acc_glv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a9967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4aa6d5c",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c59d3090",
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm_train_acc_glv = []\n",
    "blstm_val_acc_glv = []\n",
    "blstm_test_acc_glv = []\n",
    "for i in range (0, 20) :\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y_enc, test_size = 0.2, random_state = i + 1)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    x_train_seq  = tokenizer.texts_to_sequences(x_train) \n",
    "    x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "    max_len = max([len(x) for x in x_train_seq])\n",
    "    x_train_pad  = pad_sequences(x_train_seq, padding = 'post', maxlen = max_len)\n",
    "    x_test_pad = pad_sequences(x_test_seq, padding = 'post', maxlen = max_len)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    word_index = tokenizer.word_index\n",
    "            \n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    \n",
    "    embedding_layer = Embedding(\n",
    "    vocab_size,\n",
    "    embedding_dim,\n",
    "    weights = [embedding_matrix],\n",
    "    input_length = max_len,\n",
    "    trainable = False\n",
    "    )\n",
    "    \n",
    "    model_glv = Sequential()\n",
    "    model_glv.add(embedding_layer)\n",
    "    model_glv.add(Bidirectional(LSTM(units = 32)))\n",
    "    model_glv.add(Dropout(0.4))\n",
    "    model_glv.add(Dense(5, activation = 'softmax'))\n",
    "\n",
    "    model_glv.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    results_glv_blstm = model_glv.fit(\n",
    "        x_train_pad, \n",
    "        y_train, \n",
    "        epochs = 10, \n",
    "        validation_split = 0.2,\n",
    "        verbose = 0\n",
    "    )\n",
    "    \n",
    "    epoch = len(results_glv_blstm.history['accuracy'])\n",
    "    blstm_train_acc_glv.append(results_glv_blstm.history['accuracy'][epoch-1])\n",
    "    blstm_val_acc_glv.append(results_glv_blstm.history['val_accuracy'][epoch-1])\n",
    "    \n",
    "    pred = model_glv.predict(x_test_pad)\n",
    "    predicted_labels = np.argmax ( pred, axis = -1 )\n",
    "    y_test_array = np.argmax ( np.array(y_test), axis = -1 )\n",
    "    test_accuracy = accuracy_score ( y_test_array, predicted_labels )\n",
    "    blstm_test_acc_glv.append(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e39675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blstm_mean_train_acc_glv = sum(blstm_train_acc_glv)/len(blstm_train_acc_glv)\n",
    "blstm_mean_val_acc_glv = sum(blstm_val_acc_glv)/len(blstm_val_acc_glv)\n",
    "blstm_mean_test_acc_glv = sum(blstm_test_acc_glv)/len(blstm_test_acc_glv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1770209a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9682031273841858, 0.8087499976158142, 0.8086499999999999)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blstm_mean_train_acc_glv, blstm_mean_val_acc_glv, blstm_mean_test_acc_glv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72e19a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f3bd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['GRU', 'LSTM', 'Bidirectional LSTM']\n",
    "train_acc_glv = [gru_mean_train_acc_glv, lstm_mean_train_acc_glv, blstm_mean_train_acc_glv]\n",
    "val_acc_glv = [gru_mean_val_acc_glv, lstm_mean_val_acc_glv, blstm_mean_val_acc_glv]\n",
    "test_acc_glv = [gru_mean_test_acc_glv, lstm_mean_test_acc_glv, blstm_mean_test_acc_glv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5b39de93",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_df = pd.DataFrame({\n",
    "    'Model' : models,\n",
    "    'Mean Train Accuracy' : train_acc_glv,\n",
    "    'Mean Validation Accuracy' : val_acc_glv,\n",
    "    'Mean Test Accuracy' : test_acc_glv\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fada54d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean Train Accuracy</th>\n",
       "      <th>Mean Validation Accuracy</th>\n",
       "      <th>Mean Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.969453</td>\n",
       "      <td>0.820312</td>\n",
       "      <td>0.81910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.962844</td>\n",
       "      <td>0.798375</td>\n",
       "      <td>0.79250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bidirectional LSTM</td>\n",
       "      <td>0.968203</td>\n",
       "      <td>0.808750</td>\n",
       "      <td>0.80865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Mean Train Accuracy  Mean Validation Accuracy  \\\n",
       "0                 GRU             0.969453                  0.820312   \n",
       "1                LSTM             0.962844                  0.798375   \n",
       "2  Bidirectional LSTM             0.968203                  0.808750   \n",
       "\n",
       "   Mean Test Accuracy  \n",
       "0             0.81910  \n",
       "1             0.79250  \n",
       "2             0.80865  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b4e27982",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_df.to_csv('Glove_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64d017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2433a51e",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3662e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de4d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate = 0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads = num_heads, key_dim = embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation = \"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44fd23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start = 0, limit = maxlen, delta = 1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88138cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32 \n",
    "num_heads = 2\n",
    "ff_dim = 32  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "19e04d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_acc, tf_val_acc,tf_test_acc = [], [], []\n",
    "for i in range(0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1 )\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x_train)\n",
    "    x_train_seq  = tokenizer.texts_to_sequences(x_train) \n",
    "    x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "    max_len = max([len(x) for x in x_train_seq])\n",
    "    x_train_pad  = pad_sequences(x_train_seq, padding = 'post', maxlen = max_len)\n",
    "    x_test_pad = pad_sequences(x_test_seq, padding = 'post', maxlen = max_len)\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    inputs = layers.Input(shape=(max_len,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embed_dim)\n",
    "    x_ = embedding_layer(inputs)\n",
    "    transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "    x_ = transformer_block(x_)\n",
    "    x_ = layers.GlobalAveragePooling1D()(x_)\n",
    "    x_ = layers.Dropout(0.2)(x_)\n",
    "    x_ = layers.Dense(50, activation=\"relu\")(x_)\n",
    "    x_ = layers.Dropout(0.2)(x_)\n",
    "    outputs = layers.Dense(5, activation=\"softmax\")(x_)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "    results_tf = model.fit(\n",
    "        x_train_pad, y_train, batch_size = 16, epochs = 3, validation_split = 0.15, verbose = 0\n",
    "    )\n",
    "    tf_train_acc.append(results_tf.history['accuracy'][2])\n",
    "    tf_val_acc.append(results_tf.history['val_accuracy'][2])\n",
    "    \n",
    "    pred = model.predict(x_test_pad)\n",
    "    predicted_labels = np.argmax ( pred, axis = -1 )\n",
    "    tf_test_acc.append(accuracy_score ( y_test, predicted_labels ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d4d29a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_mean_train_acc = sum(tf_train_acc)/len(tf_train_acc)\n",
    "tf_mean_val_acc = sum(tf_val_acc)/len(tf_val_acc)\n",
    "tf_mean_test_acc = sum(tf_test_acc)/len(tf_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5ccdb761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9955294042825699, 0.9028333276510239, 0.8947499999999999)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_mean_train_acc, tf_mean_val_acc, tf_mean_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96662c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "630709b3",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "382fb635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "116195f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "train = { 'text' : x_train, 'label' : y_train }\n",
    "test = { 'text' : x_test, 'label' : y_test }\n",
    "train_data = datasets.Dataset.from_dict(train)\n",
    "test_data = datasets.Dataset.from_dict(test)\n",
    "data = datasets.DatasetDict( {\"train\" : train_data, \"test\" : test_data } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b932f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_bert = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd0c9014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec066b7f6e3497da8c213612a3e02ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d7a12c1b6c46d49ff8894110453e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=True)\n",
    "\n",
    "tokenized_data = data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5070770",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at C:\\Users\\PCZ/.cache\\huggingface\\transformers\\3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at C:\\Users\\PCZ/.cache\\huggingface\\transformers\\a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(model_name_bert, num_labels = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ca1c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"Accuracy\": acc, \"F1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a1c2705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = './Bert_Results',\n",
    "    learning_rate = 2e-5,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = \"F1\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    num_train_epochs = 2,\n",
    "    weight_decay = 0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84015d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_data[\"train\"],\n",
    "    eval_dataset = tokenized_data[\"test\"],\n",
    "    tokenizer = tokenizer,\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d589c85",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running training *****\n",
      "  Num examples = 4000\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 2:49:55, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.942700</td>\n",
       "      <td>0.484115</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.841882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.273300</td>\n",
       "      <td>0.402365</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.876178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./Bert_Results\\checkpoint-500\n",
      "Configuration saved in ./Bert_Results\\checkpoint-500\\config.json\n",
      "Model weights saved in ./Bert_Results\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in ./Bert_Results\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in ./Bert_Results\\checkpoint-500\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./Bert_Results\\checkpoint-1000\n",
      "Configuration saved in ./Bert_Results\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./Bert_Results\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in ./Bert_Results\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in ./Bert_Results\\checkpoint-1000\\special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./Bert_Results\\checkpoint-1000 (score: 0.8761784191911361).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=0.6079967956542969, metrics={'train_runtime': 10270.5837, 'train_samples_per_second': 0.779, 'train_steps_per_second': 0.097, 'total_flos': 365409431567856.0, 'train_loss': 0.6079967956542969, 'epoch': 2.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda1f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

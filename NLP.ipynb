{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f9dfec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PCZ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PCZ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PCZ\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31c7fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb773dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth1_url1 = \"https://www.gutenberg.org/files/786/786-0.txt\"\n",
    "auth1_url2 = \"https://www.gutenberg.org/files/564/564-0.txt\"\n",
    "auth1_url3 = \"https://www.gutenberg.org/files/675/675-0.txt\"\n",
    "auth1_url4 = \"https://www.gutenberg.org/files/98/98-0.txt\"\n",
    "auth1_url5 = \"https://www.gutenberg.org/files/650/650-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f9d00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth2_url1 = \"https://www.gutenberg.org/files/141/141-0.txt\"\n",
    "auth2_url2 = \"https://www.gutenberg.org/cache/epub/21839/pg21839.txt\"\n",
    "auth2_url3 = \"https://www.gutenberg.org/cache/epub/42671/pg42671.txt\"\n",
    "auth2_url4 = \"https://www.gutenberg.org/cache/epub/105/pg105.txt\"\n",
    "auth2_url5 = \"https://www.gutenberg.org/files/121/121-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a159e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth3_url1 = \"https://www.gutenberg.org/files/108/108-0.txt\"\n",
    "auth3_url2 = \"https://www.gutenberg.org/files/834/834-0.txt\"\n",
    "auth3_url3 = \"https://www.gutenberg.org/files/903/903-0.txt\"\n",
    "auth3_url4 = \"https://www.gutenberg.org/files/48320/48320-0.txt\"\n",
    "auth3_url5 = \"https://www.gutenberg.org/files/54109/54109-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d9cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth4_url1 = \"https://www.gutenberg.org/files/28289/28289-0.txt\"\n",
    "auth4_url2 = \"https://www.gutenberg.org/cache/epub/17780/pg17780.txt\"\n",
    "auth4_url3 = \"https://www.gutenberg.org/files/550/550-0.txt\"\n",
    "auth4_url4 = \"https://www.gutenberg.org/cache/epub/47025/pg47025.txt\"\n",
    "auth4_url5 = \"https://www.gutenberg.org/files/10762/10762.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1689eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth5_url1 = \"https://www.gutenberg.org/cache/epub/60278/pg60278.txt\"\n",
    "auth5_url2 = \"https://www.gutenberg.org/cache/epub/66837/pg66837.txt\"\n",
    "auth5_url3 = \"https://www.gutenberg.org/files/60327/60327-0.txt\"\n",
    "auth5_url4 = \"https://www.gutenberg.org/files/3474/3474-0.txt\"\n",
    "auth5_url5 = \"https://www.gutenberg.org/cache/epub/27180/pg27180.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87108837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fragments(url, L):\n",
    "    #Read the file\n",
    "    file = urllib.request.urlopen(url)\n",
    "    lines = []\n",
    "    for line in file :\n",
    "        decoded_line = line.decode(\"utf-8\")\n",
    "        lines.append(decoded_line.strip())\n",
    "    \n",
    "    #Change the letters to lower case\n",
    "    raw_docs = [doc.lower() for doc in lines]\n",
    "    while (\"\" in raw_docs) :\n",
    "        raw_docs.remove(\"\")\n",
    "    \n",
    "    #Word tokenization\n",
    "    tokenized_doc = [word_tokenize(doc) for doc in raw_docs]\n",
    "    \n",
    "    #Remove the punctuations\n",
    "    regex = re.compile('[%s]'% re.escape(string.punctuation))\n",
    "    tokenized_docs_no_punc = []\n",
    "    for review in tokenized_doc :\n",
    "        new_review = []\n",
    "        for token in review :\n",
    "            new_token = regex.sub(u'', token)\n",
    "            if not new_token == u'' :\n",
    "                new_review.append(new_token)\n",
    "        tokenized_docs_no_punc.append(new_review)\n",
    "    \n",
    "    puncs = [\"’\", \"‘\", \"“\", \"”\"]\n",
    "    for punc in puncs :\n",
    "        for line in tokenized_docs_no_punc :\n",
    "            while(punc in line) :\n",
    "                line.remove(punc)\n",
    "    \n",
    "    #Remove the stop words\n",
    "    tokenized_doc_no_sw = []\n",
    "    for doc in tokenized_docs_no_punc :\n",
    "        new_term_vector = []\n",
    "        for word in doc :\n",
    "            if not word in stopwords.words('english') :\n",
    "                new_term_vector.append(word)\n",
    "        tokenized_doc_no_sw.append(new_term_vector)\n",
    "    \n",
    "    lists = []\n",
    "    for line in tokenized_doc_no_sw:\n",
    "        lines = []\n",
    "        for word in line:\n",
    "            lines.append(\"\".join(u for u in word if u not in (\"—\")))\n",
    "        lists.append(lines)\n",
    "    \n",
    "    #Use the lemmantization to get the root words\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    pre_docs = []\n",
    "    for doc in lists :\n",
    "        final_doc = []\n",
    "        for word in doc :\n",
    "            final_doc.append(wordnet.lemmatize(word))\n",
    "        pre_docs.append(final_doc)\n",
    "    \n",
    "    #Extracting L number of fragments in size of 200\n",
    "    final_list = []\n",
    "    i = 199\n",
    "    while len(final_list) < 200 :\n",
    "            line = pre_docs[i+1]\n",
    "            while len(line) <= L:\n",
    "                i = i + 2\n",
    "                for word in pre_docs[i]:\n",
    "                    line.append(word)\n",
    "            final_list.append(' '.join(line[0:L]))\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b218f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57f5b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth1_list1 = extract_fragments(auth1_url1, L)\n",
    "auth1_list2 = extract_fragments(auth1_url2, L)\n",
    "auth1_list3 = extract_fragments(auth1_url3, L)\n",
    "auth1_list4 = extract_fragments(auth1_url4, L)\n",
    "auth1_list5 = extract_fragments(auth1_url5, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96b72b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [*auth1_list1, *auth1_list2, *auth1_list3, *auth1_list4, *auth1_list5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74f2869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth2_list1 = extract_fragments(auth2_url1, L)\n",
    "auth2_list2 = extract_fragments(auth2_url2, L)\n",
    "auth2_list3 = extract_fragments(auth2_url3, L)\n",
    "auth2_list4 = extract_fragments(auth2_url4, L)\n",
    "auth2_list5 = extract_fragments(auth2_url5, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad1d7436",
   "metadata": {},
   "outputs": [],
   "source": [
    "list2 = [*auth2_list1, *auth2_list2, *auth2_list3, *auth2_list4, *auth2_list5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cb8c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth3_list1 = extract_fragments(auth3_url1, L)\n",
    "auth3_list2 = extract_fragments(auth3_url2, L)\n",
    "auth3_list3 = extract_fragments(auth3_url3, L)\n",
    "auth3_list4 = extract_fragments(auth3_url4, L)\n",
    "auth3_list5 = extract_fragments(auth3_url5, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ddc6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "list3 = [*auth3_list1, *auth3_list2, *auth3_list3, *auth3_list4, *auth3_list5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d60b6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth4_list1 = extract_fragments(auth4_url1, L)\n",
    "auth4_list2 = extract_fragments(auth4_url2, L)\n",
    "auth4_list3 = extract_fragments(auth4_url3, L)\n",
    "auth4_list4 = extract_fragments(auth4_url4, L)\n",
    "auth4_list5 = extract_fragments(auth4_url5, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e9fdadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list4 = [*auth4_list1, *auth4_list2, *auth4_list3, *auth4_list4, *auth4_list5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da4caa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth5_list1 = extract_fragments(auth5_url1, L)\n",
    "auth5_list2 = extract_fragments(auth5_url2, L)\n",
    "auth5_list3 = extract_fragments(auth5_url3, L)\n",
    "auth5_list4 = extract_fragments(auth5_url4, L)\n",
    "auth5_list5 = extract_fragments(auth5_url5, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02b175e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list5 = [*auth5_list1, *auth5_list2, *auth5_list3, *auth5_list4, *auth5_list5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d116d3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "x = [*list1, *list2, *list3, *list4, *list5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ee20ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,\n",
       " 'beginning sunbeam bitzer corner row side row advance caught end receive deeper lustrous colour sun shone ray appeared draw little colour ever possessed lash bringing immediate contrast something might mere continuation sandy freckle forehead looked though cut would bleed white quadruped graminivorous forty teeth namely twentyfour grinder country shed hoof')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x), x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d05d16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = ['Charles Dickens', 'Jane Austen', 'Sir Arthur Conan Doyle', 'George Eliot', 'Hugh Walpole']\n",
    "target = []\n",
    "for author in authors :\n",
    "    for i in range(0, 1000):\n",
    "        target.append(author)\n",
    "y = LabelEncoder().fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0dfb28bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, {0, 1, 2, 3, 4})"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y), set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a116bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame({\n",
    "    'Extracted Fragments' : [],\n",
    "    'Author' : []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ede00436",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(x)) :\n",
    "    data_df = data_df.append({\n",
    "        'Extracted Fragments' : x[i],\n",
    "        'Author' : target[i],\n",
    "    }, ignore_index = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9eb47602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Extracted Fragments</th>\n",
       "      <th>Author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beginning sunbeam bitzer corner row side row a...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iron age known mark mouth thus much bitzer gir...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continue fistic phraseology genius coming scra...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ventured answer paper room would paint must pa...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>general conviction time sir always feeble stra...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>robin rate made meaning clear wish regard comp...</td>\n",
       "      <td>Hugh Walpole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>omitted mine came back stranger ready anything...</td>\n",
       "      <td>Hugh Walpole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>see please shall course disguise position worl...</td>\n",
       "      <td>Hugh Walpole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>end would father said show stiff back white mo...</td>\n",
       "      <td>Hugh Walpole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>felt confinement wished something broader well...</td>\n",
       "      <td>Hugh Walpole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Extracted Fragments           Author\n",
       "0     beginning sunbeam bitzer corner row side row a...  Charles Dickens\n",
       "1     iron age known mark mouth thus much bitzer gir...  Charles Dickens\n",
       "2     continue fistic phraseology genius coming scra...  Charles Dickens\n",
       "3     ventured answer paper room would paint must pa...  Charles Dickens\n",
       "4     general conviction time sir always feeble stra...  Charles Dickens\n",
       "...                                                 ...              ...\n",
       "4995  robin rate made meaning clear wish regard comp...     Hugh Walpole\n",
       "4996  omitted mine came back stranger ready anything...     Hugh Walpole\n",
       "4997  see please shall course disguise position worl...     Hugh Walpole\n",
       "4998  end would father said show stiff back white mo...     Hugh Walpole\n",
       "4999  felt confinement wished something broader well...     Hugh Walpole\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "622effa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_csv('Dataset_L50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b26dbd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5428d1e5",
   "metadata": {},
   "source": [
    "## BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8148d8b4",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4dc5b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "x_train_bow = bow.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "27edc188",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_par = {\n",
    "    'penalty' : ['l2'],\n",
    "    'C' : [0.1, 1.0, 10.0],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'max_iter' : [100, 200, 300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "01c60814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "lr_grid = GridSearchCV(LR, lr_par, refit = True, n_jobs=-1, cv=5)\n",
    "lr_grid.fit(x_train_bow, y_train)\n",
    "opt_par = lr_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8a2debb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C = 10.0, max_iter = 100, penalty = 'l2', solver = 'newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e572d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_acc = []\n",
    "lr_test_acc = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    bow = CountVectorizer()\n",
    "    x_train_bow = bow.fit_transform(x_train)\n",
    "    x_test_bow = bow.transform(x_test)\n",
    "    LR.fit(x_train_bow, y_train)\n",
    "    y_pred = LR.predict(x_test_bow)\n",
    "    y_train_pred = LR.predict(x_train_bow)\n",
    "    lr_train_acc.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    lr_test_acc.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e8c2ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mean_train_acc_bow = sum(lr_train_acc)/len(lr_train_acc)\n",
    "lr_mean_test_acc_bow = sum(lr_test_acc)/len(lr_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "812fd6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9194000000000001)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mean_train_acc_bow, lr_mean_test_acc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d869eafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ebce1d5",
   "metadata": {},
   "source": [
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d02614ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train_bow = bow.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5660a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_par = [\n",
    "   { 'C' : [0.1, 1.0, 10.0],\n",
    "    'kernel' : ['linear']\n",
    "   },\n",
    "   { 'C' : [0.1, 1.0, 10.0],\n",
    "    'kernel' : ['poly'],\n",
    "    'degree' : [2, 3, 4],\n",
    "    'gamma' : ['scale', 'auto']\n",
    "   },\n",
    "   { 'C' : [0.1, 1.0, 10.0],\n",
    "    'kernel' : ['rbf', 'sigmoid'],\n",
    "    'gamma' : ['scale', 'auto']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "62259f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = SVC()\n",
    "svm_grid = GridSearchCV(SVM, svm_par, refit = True, n_jobs=-1, cv=5)\n",
    "svm_grid.fit(x_train_bow, y_train)\n",
    "opt_par = svm_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a130f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC( C = 0.1, kernel = 'linear' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d1283699",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train_acc = []\n",
    "svm_test_acc = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    bow = CountVectorizer()\n",
    "    x_train_bow = bow.fit_transform(x_train)\n",
    "    x_test_bow = bow.transform(x_test)\n",
    "    SVM.fit(x_train_bow, y_train)\n",
    "    y_pred = SVM.predict(x_test_bow)\n",
    "    y_train_pred = SVM.predict(x_train_bow)\n",
    "    svm_train_acc.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    svm_test_acc.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b927fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mean_train_acc_bow = sum(svm_train_acc)/len(svm_train_acc)\n",
    "svm_mean_test_acc_bow = sum(svm_test_acc)/len(svm_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "726b9fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9015500000000001)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_mean_train_acc_bow, svm_mean_test_acc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b518d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21b2c55b",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "782c2a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train_bow = bow.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "82d9ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_par = {\n",
    "    'n_estimators' : [50, 100, 200],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [8, 16, 32],\n",
    "    'max_features' : ['sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "35f0485f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 32,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(RF, rf_par, refit = True, n_jobs=-1, cv=5)\n",
    "rf_grid.fit(x_train_bow, y_train)\n",
    "opt_par = rf_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0953f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(criterion = 'gini', max_depth = 32, max_features = 'log2', n_estimators = 200 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9bcd9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_acc = []\n",
    "rf_test_acc = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    bow = CountVectorizer()\n",
    "    x_train_bow = bow.fit_transform(x_train)\n",
    "    x_test_bow = bow.transform(x_test)\n",
    "    RF.fit(x_train_bow, y_train)\n",
    "    y_pred = RF.predict(x_test_bow)\n",
    "    y_train_pred = RF.predict(x_train_bow)\n",
    "    rf_train_acc.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    rf_test_acc.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fa5206f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_mean_train_acc_bow = sum(rf_train_acc)/len(rf_train_acc)\n",
    "rf_mean_test_acc_bow = sum(rf_test_acc)/len(rf_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1a1bd0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9998499999999998, 0.8686999999999998)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mean_train_acc_bow, rf_mean_test_acc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c290946a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "158c3e80",
   "metadata": {},
   "source": [
    "Naive Bays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c2fcc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "77ce61da",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_acc = []\n",
    "nb_test_acc = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    bow = CountVectorizer()\n",
    "    x_train_bow = bow.fit_transform(x_train)\n",
    "    x_test_bow = bow.transform(x_test)\n",
    "    NB.fit(x_train_bow, y_train)\n",
    "    y_pred = NB.predict(x_test_bow)\n",
    "    y_train_pred = NB.predict(x_train_bow)\n",
    "    nb_train_acc.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    nb_test_acc.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "75646e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_mean_train_acc_bow = sum(nb_train_acc)/len(nb_train_acc)\n",
    "nb_mean_test_acc_bow = sum(nb_test_acc)/len(nb_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0e6c636e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.991, 0.9328000000000001)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_mean_train_acc_bow, nb_mean_test_acc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699e1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70265bd5",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e185a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = CountVectorizer()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train_bow = bow.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5fd4a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_par = {\n",
    "    'n_estimators' : [20, 50, 100],\n",
    "    'use_label_encoder' : [False],\n",
    "    'max_depth' : [8, 16, 32],\n",
    "    'learning_rate' : [0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d50e2b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:58:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 8,\n",
       " 'n_estimators': 100,\n",
       " 'use_label_encoder': False}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB = XGBClassifier()\n",
    "xgb_grid = GridSearchCV(XGB, xgb_par, refit = True, n_jobs=-1, cv=5)\n",
    "xgb_grid.fit(x_train_bow, y_train)\n",
    "opt_par = xgb_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "89fad4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(learning_rate = 0.1, max_depth = 8, n_estimators = 100, use_label_encoder = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "16ffaf9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:00:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:00:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:00:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:01:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:01:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:01:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:01:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:02:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:02:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:02:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:02:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:03:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:03:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:03:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:03:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:04:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:04:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:04:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:04:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_train_acc = []\n",
    "xgb_test_acc = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    bow = CountVectorizer()\n",
    "    x_train_bow = bow.fit_transform(x_train)\n",
    "    x_test_bow = bow.transform(x_test)\n",
    "    XGB.fit(x_train_bow, y_train)\n",
    "    y_pred = XGB.predict(x_test_bow)\n",
    "    y_train_pred = XGB.predict(x_train_bow)\n",
    "    xgb_train_acc.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    xgb_test_acc.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d23de49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_mean_train_acc_bow = sum(xgb_train_acc)/len(xgb_train_acc)\n",
    "xgb_mean_test_acc_bow = sum(xgb_test_acc)/len(xgb_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6380840f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.984675, 0.8283499999999998)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mean_train_acc_bow, xgb_mean_test_acc_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754619d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "435b498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['Logistic Regression', 'Support Vector Machine', 'Random Forest', 'Naive Bayes', 'XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c19bfd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_df = pd.DataFrame({\n",
    "    'Algorithm' : [], 'Mean Train Accuracy' : [], 'Mean Test Accuracy' :[]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "76120d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_acc_bow = [lr_mean_train_acc_bow, svm_mean_train_acc_bow, rf_mean_train_acc_bow,\n",
    "                      nb_mean_train_acc_bow, xgb_mean_train_acc_bow]\n",
    "mean_test_acc_bow = [lr_mean_test_acc_bow, svm_mean_test_acc_bow, rf_mean_test_acc_bow,\n",
    "                    nb_mean_test_acc_bow, xgb_mean_test_acc_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9a8681ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(algorithms)) :\n",
    "    bow_df = bow_df.append({\n",
    "        'Algorithm' : algorithms[i],\n",
    "        'Mean Train Accuracy' : mean_train_acc_bow[i],\n",
    "        'Mean Test Accuracy' : mean_test_acc_bow[i],\n",
    "    }, ignore_index = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "264a906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Mean Train Accuracy</th>\n",
       "      <th>Mean Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.91940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.90155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>0.86870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>0.93280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.984675</td>\n",
       "      <td>0.82835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  Mean Train Accuracy  Mean Test Accuracy\n",
       "0     Logistic Regression             1.000000             0.91940\n",
       "1  Support Vector Machine             1.000000             0.90155\n",
       "2           Random Forest             0.999850             0.86870\n",
       "3             Naive Bayes             0.991000             0.93280\n",
       "4                 XGBoost             0.984675             0.82835"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "048dafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_df.to_csv('BOW_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebdb2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae388c99",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24ec50",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9e744fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(use_idf=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train_tf = tf_idf.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f980cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_par = {\n",
    "    'penalty' : ['l2'],\n",
    "    'C' : [0.1, 1.0, 10.0],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'max_iter' : [100, 200, 300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "551236c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10.0, 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "lr_grid = GridSearchCV(LR, lr_par, refit = True, n_jobs=-1, cv=5)\n",
    "lr_grid.fit(x_train_tf, y_train)\n",
    "opt_par = lr_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b7b8369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C = 10.0, max_iter = 200, penalty = 'l2', solver = 'saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2cd631a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_train_acc = []\n",
    "lr_test_acc = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    tf_idf = TfidfVectorizer(use_idf=True)\n",
    "    x_train_tf = tf_idf.fit_transform(x_train)\n",
    "    x_test_tf = tf_idf.transform(x_test)\n",
    "    LR.fit(x_train_tf, y_train)\n",
    "    y_pred = LR.predict(x_test_tf)\n",
    "    y_train_pred = LR.predict(x_train_tf)\n",
    "    lr_train_acc.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    lr_test_acc.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "165f524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mean_train_acc_tf = sum(lr_train_acc)/len(lr_train_acc)\n",
    "lr_mean_test_acc_tf = sum(lr_test_acc)/len(lr_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "efd7471e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9441)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_mean_train_acc_tf, lr_mean_test_acc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edd91db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "651464be",
   "metadata": {},
   "source": [
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e669da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(use_idf=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train_tf = tf_idf.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8dc283ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_par = [\n",
    "   { 'C' : [0.1, 1.0, 10.0],\n",
    "    'kernel' : ['linear']\n",
    "   },\n",
    "   { 'C' : [0.1, 1.0, 10.0],\n",
    "    'kernel' : ['poly'],\n",
    "    'degree' : [2, 3, 4],\n",
    "    'gamma' : ['scale', 'auto']\n",
    "   },\n",
    "   { 'C' : [0.1, 1.0, 10.0],\n",
    "    'kernel' : ['rbf', 'sigmoid'],\n",
    "    'gamma' : ['scale', 'auto']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "29dc34f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = SVC()\n",
    "svm_grid = GridSearchCV(SVM, svm_par, refit = True, n_jobs=-1, cv=5)\n",
    "svm_grid.fit(x_train_tf, y_train)\n",
    "opt_par = svm_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8378f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(C = 1.0, kernel = 'linear' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1ac25b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_train_acc = []\n",
    "svm_test_acc = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    tf_idf = TfidfVectorizer(use_idf=True)\n",
    "    x_train_tf = tf_idf.fit_transform(x_train)\n",
    "    x_test_tf = tf_idf.transform(x_test)\n",
    "    SVM.fit(x_train_tf, y_train)\n",
    "    y_pred = SVM.predict(x_test_tf)\n",
    "    y_train_pred = SVM.predict(x_train_tf)\n",
    "    svm_train_acc.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    svm_test_acc.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ee7e108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_mean_train_acc_tf = sum(svm_train_acc)/len(svm_train_acc)\n",
    "svm_mean_test_acc_tf = sum(svm_test_acc)/len(svm_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c6523751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9992124999999998, 0.9400499999999999)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_mean_train_acc_tf, svm_mean_test_acc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039cfd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba3a02e4",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bbeab467",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(use_idf=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "x_train_tf = tf_idf.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6db82ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_par = {\n",
    "    'n_estimators' : [50, 100, 200],\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [8, 16, 32],\n",
    "    'max_features' : ['sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3f6c9bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 32,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(RF, rf_par, refit = True, n_jobs=-1, cv=5)\n",
    "rf_grid.fit(x_train_tf, y_train)\n",
    "opt_par = rf_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a0285ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(criterion = 'gini', max_depth = 32, max_features = 'log2', n_estimators = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "39179ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_acc = []\n",
    "rf_test_acc = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    tf_idf = TfidfVectorizer(use_idf=True)\n",
    "    x_train_tf = tf_idf.fit_transform(x_train)\n",
    "    x_test_tf = tf_idf.transform(x_test)\n",
    "    RF.fit(x_train_tf, y_train)\n",
    "    y_pred = RF.predict(x_test_tf)\n",
    "    y_train_pred = RF.predict(x_train_tf)\n",
    "    rf_train_acc.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    rf_test_acc.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "01b7c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_mean_train_acc_tf = sum(rf_train_acc)/len(rf_train_acc)\n",
    "rf_mean_test_acc_tf = sum(rf_test_acc)/len(rf_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d46b0a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98955, 0.7921)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mean_train_acc_tf, rf_mean_test_acc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3835b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b14555e",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "796f3524",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "eba03991",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_acc = []\n",
    "nb_test_acc = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    tf_idf = TfidfVectorizer(use_idf=True)\n",
    "    x_train_tf = tf_idf.fit_transform(x_train)\n",
    "    x_test_tf = tf_idf.transform(x_test)\n",
    "    NB.fit(x_train_tf, y_train)\n",
    "    y_pred = NB.predict(x_test_tf)\n",
    "    y_train_pred = NB.predict(x_train_tf)\n",
    "    nb_train_acc.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    nb_test_acc.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ee7a0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_mean_train_acc_tf = sum(nb_train_acc)/len(nb_train_acc)\n",
    "nb_mean_test_acc_tf = sum(nb_test_acc)/len(nb_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e8d50c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9757000000000001, 0.8935000000000001)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_mean_train_acc_tf, nb_mean_test_acc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ba62c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88d6bc7f",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f9da481d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(use_idf=True)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train_tf = tf_idf.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1f079e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_par = {\n",
    "    'n_estimators' : [20, 50, 100],\n",
    "    'use_label_encoder' : [False],\n",
    "    'max_depth' : [8, 16, 32],\n",
    "    'learning_rate' : [0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ae115840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:43:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 8,\n",
       " 'n_estimators': 100,\n",
       " 'use_label_encoder': False}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB = XGBClassifier()\n",
    "xgb_grid = GridSearchCV(XGB, xgb_par, refit = True, n_jobs=-1, cv=5)\n",
    "xgb_grid.fit(x_train_tf, y_train)\n",
    "opt_par = xgb_grid.best_params_\n",
    "opt_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "88c82cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = XGBClassifier(learning_rate = 0.1, max_depth = 8, n_estimators = 100, use_label_encoder = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e2242119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:44:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:45:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:46:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:47:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:48:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:49:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:50:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:51:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:52:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:53:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:54:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:55:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:56:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:57:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:58:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_train_acc = []\n",
    "xgb_test_acc = []\n",
    "for i in range (0, 20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = i+1)\n",
    "    tf_idf = TfidfVectorizer(use_idf=True)\n",
    "    x_train_tf = tf_idf.fit_transform(x_train)\n",
    "    x_test_tf = tf_idf.transform(x_test)\n",
    "    XGB.fit(x_train_tf, y_train)\n",
    "    y_pred = XGB.predict(x_test_tf)\n",
    "    y_train_pred = XGB.predict(x_train_tf)\n",
    "    xgb_train_acc.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    xgb_test_acc.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7e8c44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_mean_train_acc_tf = sum(xgb_train_acc)/len(xgb_train_acc)\n",
    "xgb_mean_test_acc_tf = sum(xgb_test_acc)/len(xgb_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "80f99672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9883624999999998, 0.8030000000000002)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mean_train_acc_tf, xgb_mean_test_acc_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d0f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ca9d5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['Logistic Regression', 'Support Vector Machine', 'Random Forest', 'Naive Bayes', 'XGBoost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2229df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = pd.DataFrame({\n",
    "    'Algorithm' : [], 'Mean Train Accuracy' : [], 'Mean Test Accuracy' :[]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1e8358e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_acc_tf = [lr_mean_train_acc_tf, svm_mean_train_acc_tf, rf_mean_train_acc_tf,\n",
    "                      nb_mean_train_acc_tf, xgb_mean_train_acc_tf]\n",
    "mean_test_acc_tf = [lr_mean_test_acc_tf, svm_mean_test_acc_tf, rf_mean_test_acc_tf,\n",
    "                    nb_mean_test_acc_tf, xgb_mean_test_acc_tf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9970486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(algorithms)) :\n",
    "    tf_df = tf_df.append({\n",
    "        'Algorithm' : algorithms[i],\n",
    "        'Mean Train Accuracy' : mean_train_acc_tf[i],\n",
    "        'Mean Test Accuracy' : mean_test_acc_tf[i],\n",
    "    }, ignore_index = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2f4545b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Mean Train Accuracy</th>\n",
       "      <th>Mean Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.94410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.999212</td>\n",
       "      <td>0.94005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.989550</td>\n",
       "      <td>0.79210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.975700</td>\n",
       "      <td>0.89350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.988362</td>\n",
       "      <td>0.80300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  Mean Train Accuracy  Mean Test Accuracy\n",
       "0     Logistic Regression             1.000000             0.94410\n",
       "1  Support Vector Machine             0.999212             0.94005\n",
       "2           Random Forest             0.989550             0.79210\n",
       "3             Naive Bayes             0.975700             0.89350\n",
       "4                 XGBoost             0.988362             0.80300"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ba55d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df.to_csv('TF-IDF_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d799cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
